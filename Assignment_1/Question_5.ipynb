{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "- Use Gutenberg and Web_text data. Find out what are the top 5 words that Shakespeare used but we do not currently use.\n",
    "- Take top 50 words from Shakespeare (all 3 books) and top 50 from Web_text (all the records).\n",
    "- Remove the words we still use today, and get the stop words list. Show the top 5 elements. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top five words we no longer use are...\n",
      "haue is mentioned 448 times\n",
      "vpon is mentioned 162 times\n",
      "brutus is mentioned 162 times\n",
      "bru is mentioned 153 times\n",
      "hath is mentioned 144 times\n"
     ]
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()\n",
    "caesarTxt = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')\n",
    "hamletTxt = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "macbethTxt = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')\n",
    "def frequency(lowerWords):\n",
    "    wordDict = dict()\n",
    "    for x in lowerWords:\n",
    "        if x in wordDict:\n",
    "            wordDict[x] = wordDict.get(x) + 1\n",
    "        else:\n",
    "            wordDict[x] = 1\n",
    "    zoo = sorted(wordDict.items(), key=lambda a: a[1], reverse = True)\n",
    "    return zoo\n",
    "\n",
    "lowCae = [word.lower() for word in caesarTxt]\n",
    "unCae = list(set(lowCae))\n",
    "lowHam = [word.lower() for word in hamletTxt]\n",
    "unHam = list(set(lowHam))\n",
    "lowMac = [word.lower() for word in macbethTxt]\n",
    "unMac = list(set(lowMac))\n",
    "allTxt = list(set(unCae + unHam + unMac))\n",
    "webs = webtext.fileids()\n",
    "\n",
    "topShake = frequency(allTxt)[0:50]\n",
    "#print(topShake)\n",
    "webTxt = []\n",
    "for x in webs:\n",
    "    txt = webtext.words(x)\n",
    "    holder = list(set(word.lower() for word in txt))\n",
    "    webTxt += holder\n",
    "unWeb = list(set(webTxt))\n",
    "unCommon = [word for word in allTxt if word not in unWeb]\n",
    "everyTxt = lowCae + lowHam + lowMac\n",
    "vals = []\n",
    "for x in unCommon:\n",
    "    vals.append([everyTxt.count(x),x])\n",
    "vals.sort(reverse=True)\n",
    "print('The top five words we no longer use are...')\n",
    "for word in vals[0:5]:\n",
    "    print(word[1],'is mentioned',word[0], 'times')\n",
    "#[print(word[1],':',word[0]) for word in vals[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('haue', 448)]\n",
      "['i', 'd', 'his', 'your', 'he', 'what', ';', 'haue', 'him', 'as', 'so', 'will', 'our', 'ham', 'all', 'thou', 'we', 'shall', 'no', 'lord', 'do', 'then', 'by']\n",
      "[(',', 7058), ('.', 4417), ('the', 2222), ('and', 2036), (\"'\", 1750), (':', 1541), ('to', 1515), ('i', 1455), ('of', 1302), ('you', 1124), ('a', 1019), ('?', 996), ('my', 914), ('that', 904), ('in', 826), ('it', 778), ('is', 769), ('not', 722), ('d', 662), ('his', 588), ('with', 557), ('this', 546), ('for', 533), ('me', 529), ('your', 528), ('but', 510), ('he', 491), ('be', 476), ('what', 458), (';', 456), ('haue', 448), ('him', 434), ('as', 427), ('so', 424), ('will', 384), ('our', 346), ('ham', 337), ('all', 321), ('thou', 312), ('we', 306), ('are', 305), ('s', 303), ('shall', 300), ('no', 297), ('lord', 293), ('-', 293), ('do', 287), ('then', 278), ('on', 276), ('by', 256)]\n",
      "50\n",
      "The top five words we no longer use are...\n",
      "('your', 528) is mentioned 0 times\n",
      "('you', 1124) is mentioned 0 times\n",
      "('with', 557) is mentioned 0 times\n",
      "('will', 384) is mentioned 0 times\n",
      "('what', 458) is mentioned 0 times\n"
     ]
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()\n",
    "caesarTxt = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')\n",
    "hamletTxt = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "macbethTxt = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')\n",
    "def frequency(lowerWords):\n",
    "    wordDict = dict()\n",
    "    for x in lowerWords:\n",
    "        if x in wordDict:\n",
    "            wordDict[x] = wordDict.get(x) + 1\n",
    "        else:\n",
    "            wordDict[x] = 1\n",
    "    zoo = sorted(wordDict.items(), key=lambda a: a[1], reverse = True)\n",
    "    return zoo\n",
    "\n",
    "lowCae = [word.lower() for word in caesarTxt]\n",
    "lowHam = [word.lower() for word in hamletTxt]\n",
    "lowMac = [word.lower() for word in macbethTxt]\n",
    "allTxt = lowCae + lowHam + lowMac\n",
    "\n",
    "topShake = frequency(allTxt)[0:50]\n",
    "topShakeWords = [word[0] for word in topShake]\n",
    "topWeb = frequency(webtext.words())[0:50]\n",
    "topWebWords = [word[0] for word in topWeb]\n",
    "\n",
    "unCommon = [item for item in topShake if item[0] not in webtext.words()]\n",
    "print(unCommon)\n",
    "unCommon = []\n",
    "for x in topShake:\n",
    "    if x[0] not in topWebWords:\n",
    "        unCommon.append(x[0])\n",
    "print(unCommon)\n",
    "unCommon = [word[0] for word[0] in topShake if word not in topWeb]\n",
    "print(unCommon)\n",
    "print(len(unCommon))\n",
    "#unCommon = [word for word in allTxt if word not in unWeb]\n",
    "everyTxt = lowCae + lowHam + lowMac\n",
    "vals = []\n",
    "for x in unCommon:\n",
    "    vals.append([everyTxt.count(x),x])\n",
    "vals.sort(reverse=True)\n",
    "print('The top five words we no longer use are...')\n",
    "for word in vals[0:5]:\n",
    "    print(word[1],'is mentioned',word[0], 'times')\n",
    "#[print(word[1],':',word[0]) for word in vals[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
